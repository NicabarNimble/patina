// Shared utilities for all scrape subcommands

pub mod code;
pub mod database;
pub mod git;
pub mod github;
pub mod layer;
pub mod sessions;

use anyhow::Result;

/// Common configuration for all scrapers
pub struct ScrapeConfig {
    pub db_path: String,
    pub force: bool,
}

impl ScrapeConfig {
    pub fn new(force: bool) -> Self {
        Self {
            db_path: database::PATINA_DB.to_string(),
            force,
        }
    }
}

/// Common stats that all scrapers return
#[derive(Debug)]
pub struct ScrapeStats {
    pub items_processed: usize,
    pub time_elapsed: std::time::Duration,
    pub database_size_kb: u64,
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::time::Duration;

    #[test]
    fn test_scrape_stats_creation() {
        let stats = ScrapeStats {
            items_processed: 100,
            time_elapsed: Duration::from_secs(5),
            database_size_kb: 1024,
        };
        assert_eq!(stats.items_processed, 100);
        assert_eq!(stats.time_elapsed.as_secs(), 5);
        assert_eq!(stats.database_size_kb, 1024);
    }
}

/// Run all scrapers in sequence (code, git, sessions, layer)
///
/// This is the default when running `patina scrape` with no subcommand.
pub fn execute_all() -> Result<()> {
    println!("ğŸ”„ Running all scrapers...\n");

    println!("ğŸ“Š [1/4] Scraping code...");
    execute_code(false, false)?;

    println!("\nğŸ“Š [2/4] Scraping git...");
    let git_stats = git::run(false)?;
    println!("  â€¢ {} commits", git_stats.items_processed);

    println!("\nğŸ“š [3/4] Scraping sessions...");
    let session_stats = sessions::run(false)?;
    println!("  â€¢ {} sessions", session_stats.items_processed);

    println!("\nğŸ“œ [4/4] Scraping layer patterns...");
    let layer_stats = layer::run(false)?;
    println!("  â€¢ {} patterns", layer_stats.items_processed);

    println!("\nâœ… All scrapers complete!");
    Ok(())
}

/// Execute code scraper for current directory
///
/// For external repos, use `patina repo update <name>` instead.
pub fn execute_code(init: bool, force: bool) -> Result<()> {
    let config = ScrapeConfig::new(force);

    if init {
        code::initialize(&config)?;
    } else {
        let stats = code::run(config)?;

        println!("\nğŸ“Š Code Extraction Summary:");
        println!("  â€¢ Items processed: {}", stats.items_processed);
        println!("  â€¢ Time elapsed: {:?}", stats.time_elapsed);
        println!("  â€¢ Database size: {} KB", stats.database_size_kb);
    }

    Ok(())
}

/// Execute git scraper with summary output
pub fn execute_git(full: bool) -> Result<()> {
    let stats = git::run(full)?;
    println!("\nğŸ“Š Git Scrape Summary:");
    println!("  â€¢ Commits processed: {}", stats.items_processed);
    println!("  â€¢ Time elapsed: {:?}", stats.time_elapsed);
    println!("  â€¢ Database size: {} KB", stats.database_size_kb);
    Ok(())
}

/// Execute sessions scraper with summary output
pub fn execute_sessions(full: bool) -> Result<()> {
    let stats = sessions::run(full)?;
    println!("\nğŸ“Š Sessions Scrape Summary:");
    println!("  â€¢ Sessions processed: {}", stats.items_processed);
    println!("  â€¢ Time elapsed: {:?}", stats.time_elapsed);
    println!("  â€¢ Database size: {} KB", stats.database_size_kb);
    Ok(())
}

/// Execute layer pattern scraper with summary output
pub fn execute_layer(full: bool) -> Result<()> {
    let stats = layer::run(full)?;
    println!("\nğŸ“Š Layer Scrape Summary:");
    println!("  â€¢ Patterns processed: {}", stats.items_processed);
    println!("  â€¢ Time elapsed: {:?}", stats.time_elapsed);
    println!("  â€¢ Database size: {} KB", stats.database_size_kb);
    Ok(())
}
