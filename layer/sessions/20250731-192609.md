# Session: setup the new layer folder structure
**ID**: 20250731-192609
**Started**: 2025-07-31T23:26:09Z
**LLM**: claude

## Previous Session Context
Last session was a test session (20250731-191904) that appears to have been very brief with no specific accomplishments documented.

## Goals
- [ ] setup the new layer folder structure

## Activity Log
### 19:26 - Session Start
Session initialized with goal: setup the new layer folder structure


### 20:51 - Update (covering since 19:26)

**Work completed:**
- Deep exploration of layer-structure-evolution.md and the core/surface/dust oxidation model
- Analyzed 50+ existing layer documents to understand organization patterns
- Studied how big tech (Google/Meta) handles documentation vs code alignment
- Designed hybrid approach: human-readable markdown with code verification
- Explored semantic search problem for accumulated patterns
- Created plan for LLM-powered pattern indexing and search

**Key decisions:**
- Keep markdown as primary source (human/LLM friendly)
- Use oxidation metadata (confidence, status, tags) for all docs
- LLMs self-index patterns as they generate them
- Start simple: basic tags → LLM summaries → rqlite full search
- Surface domains form organically like "paths where people walk"
- Design atomic docs (~100-200 lines) focused on single concepts

**Challenges faced:**
- Initial approach too code-heavy, forgot human language priority
- Overwhelming scope - needed to find smallest useful step
- Balancing immediate value vs long-term vision
- Understanding how to make patterns semantically searchable

**Patterns observed:**
- Big tech uses structured docs + automated verification
- LLMs excel at extracting structure from human text
- Oxidation metaphor guides everything: fresh → weathered → core/dust
- Semantic search is THE key problem for pattern reuse
- Implementation should be gradual: manual → assisted → automatic

### 21:27 - Update (covering since 20:51)

**Work completed:**
- Captured Meta/Google/Amazon approaches to doc-code alignment
- Developed question-based naming pattern (why-x, how-y, when-z)
- Established domain isolation principle - each layer/ is self-contained
- Explored how other tech companies handle knowledge (Netflix, Stripe, GitLab, Spotify, HashiCorp)
- Synthesized Spotify's squad/guild model with Stripe's executable docs for Patina
- Designed actionable core/ improvements with executable proofs
- Reviewed 50+ existing layer documents to understand current organization
- Identified that surface domains should form organically like "paths where people walk"
- Created plan for 5 atomic surface docs about semantic search

**Key decisions:**
- Core docs need executable verification (bash blocks that test claims)
- Question-based naming makes docs discoverable (e.g., "why-patina-needs-semantic-search.md")
- Each domain is isolated - LLM only sees current project's layer/
- Meta's organic approach fits Patina better than Google's process-heavy style
- Core should only contain implemented, proven patterns
- Start with core/ cleanup before moving sessions to surface/raw/
- LLMs self-index patterns as they generate them (no separate indexing step)
- Semantic search implementation: manual tags → LLM summaries → rqlite

**Challenges faced:**
- Initial big tech approaches felt too heavyweight
- Balancing aspiration with current implementation reality
- Finding the smallest actionable step for core/ improvement
- Overwhelming scope of semantic search - needed phased approach
- Understanding that markdown must remain primary (not code-first)

**Patterns observed:**
- Spotify's squad/guild model maps well to Patina's domain/core structure
- Executable documentation (Stripe-style) provides verification without bureaucracy
- Question-based files create self-documenting structure
- Domain isolation enables focused, high-quality context
- Bottom-up pattern emergence aligns with oxidation metaphor
- Since LLMs generate patterns, they can pre-index with perfect semantic tags
- The flow: Human asks → LLM generates pattern → Pattern self-indexes → Future LLMs find it

**Next steps identified:**
- Reorganize core/ with executable proofs and question-based names
- Move sessions/ to surface/raw/ as first implementation step
- Create surface/explorations/ for semantic search design docs
- Build simple tag-based search before attempting full semantic search
