# Session: analysis-patina-current-truth-and-vision
**ID**: 20251116-091942
**Started**: 2025-11-16T14:19:42Z
**LLM**: claude
**Git Branch**: neuro-symbolic-knowledge-system
**Session Tag**: session-20251116-091942-start
**Starting Commit**: 5ba90afe087fd9e06ef4126b3b4d995d99cfa07d

## Previous Session Context
Fixed USearch index rebuild blocker (decoupled SQLite INSERT from index add operations), implemented quality filtering system that improved query success from 3/5 to 5/5, and built model abstraction layer for easy model switching. Added 24 high-quality documentation observations (2.4% of total) that fixed 40% of broken queries, proving quality > quantity. Discovered critical Mac-first hardware constraint (Apple Silicon, not NVIDIA/CUDA) affecting model selection strategy. Topic 0 complete with Phase 0A infrastructure ready for benchmarking.

## Goals
- [x] analysis-patina-current-truth-and-vision (model selection criteria)

## Activity Log
### 09:19 - Session Start
Session initialized with goal: analysis-patina-current-truth-and-vision
Working on branch: neuro-symbolic-knowledge-system
Tagged as: session-20251116-091942-start

### 09:45 - Model Selection Criteria Update

**Work Completed:**

1. **Reviewed Previous Sessions & Git History**
   - Analyzed last session (20251116-073958): Topic 0 complete, quality filtering working
   - Found ONNX decision rationale in session 20251030-151418
   - Key finding: Low similarity scores (0.40-0.60) need diagnosis

2. **Updated Model Selection Criteria** (Commit: 158772c)
   - **Philosophy shift**: On-device distribution > bleeding-edge performance
   - **Priority order**: Size (1st) → Stability (2nd) → Mac ecosystem (3rd) → Quality (4th)
   - Added model comparison table with sizes, maturity, GitHub LFS requirements
   - Documented why 768-dim models rejected (105MB, 5x size, requires LFS)

3. **Phase 0A Decision: Test bge-small-en-v1.5**
   - 32.4MB INT8 (40% larger but GitHub-friendly, no LFS)
   - Sept 2023 release (14 months old, production-proven)
   - 384 dims (same as current, no USearch rebuild needed)
   - BGE family quality (better retrieval than MiniLM)

4. **Added Meta-Observation: "Why ONNX?" Validation Use Case**
   - Answered from session 20251030-151418
   - Rationale: Cross-platform (Mac+Linux+Windows), pure Rust, no Python
   - Trade-off: 30-50ms (ONNX) vs 20ms (CoreML) for portability
   - **This is exactly the kind of question Patina should answer!**
   - Added future test query: `patina query semantic "why did we choose ONNX?"`

5. **Updated Model Registry** (resources/models/registry.toml)
   - Added bge-small-en-v1.5 definition with size/maturity metadata
   - Added size_int8 and maturity fields to bge-base-en-v1.5
   - Documented all models with GitHub LFS requirements

6. **Updated Config Template** (.patina/config.toml)
   - Listed all 5 models with sizes and LFS requirements
   - Marked bge-small-en-v1.5 as "Phase 0A test candidate"

**Key Decisions:**

1. **Size + Mac + Stability > Bleeding-Edge**
   - Model size is #1 priority (GitHub, CI, distribution)
   - Stability (≤2023 release) prevents churn
   - Mac compatibility required (ONNX Runtime on Apple Silicon)

2. **Rejected 768-dim models (bge-base, e5-base, gte-base)**
   - 105MB requires GitHub LFS (distribution complexity)
   - 5x size increase for ~5-8% quality gain
   - 768 dims requires USearch rebuild (infrastructure change)
   - Violates on-device first principle

3. **bge-small-en-v1.5 is the Right Test**
   - Meets all hard constraints (size, stability, Mac)
   - Low-risk upgrade path (same dimensions)
   - If it fails: stay with current, focus on data quality

**Patterns Observed:**

1. **User Constraint Drives Architecture**
   - "Size + Mac ecosystem" constraint ruled out 3 models instantly
   - On-device distribution requires <50MB threshold
   - GitHub LFS is a distribution tax (avoid if possible)

2. **Stability > Novelty for Production**
   - 14 months old (Sept 2023) is perfect maturity
   - Too new (<6 months) = unproven, risky
   - Too old (pre-2020) = outdated quality

3. **Same Dimensions = Low-Risk Upgrade**
   - 384→384 dims: just re-embed observations
   - 384→768 dims: rebuild USearch index (infrastructure risk)
   - Prefer quality improvements that minimize infrastructure changes

**Meta-Learning: Patina Validation Use Case**

User asked: "Why did we pick ONNX previously?"

This revealed a perfect validation scenario:
- Historical decision (session 20251030-151418)
- Context-rich answer (cross-platform, Rust, no Python)
- Exactly what Patina should retrieve quickly

Added to analysis as future test query. When Phase 0A works, we should be able to answer this instantly.

**Status**: Model selection criteria complete, ready for Phase 0A execution


### 15:19 - Update (covering since session start)

**Git Activity:**
- Commits this session:        0
- Files changed: 2
- Last commit: 5 hours ago

**Work Completed:**

1. **Reviewed CLAUDE.md vs analysis-patina-current-truth-and-vision.md**
   - Analysis doc is north star for what's real vs aspirational
   - Identified gaps: CLAUDE.md missing neuro-symbolic reasoning, core commands, ONNX architecture
   - PROJECT_DESIGN.toml was removed from init workflow (Oct 21, 2025) - users get ENVIRONMENT.toml instead

2. **Fixed CLAUDE.md Design Documents section**
   - Removed PROJECT_DESIGN.toml reference (outdated - removed from user workflow)
   - Removed modular-architecture-plan.md (Dagger-era doc, no longer relevant)
   - Kept ENVIRONMENT.toml (auto-generated environment snapshot)
   - Kept pattern-selection-framework.md (core teaching doc)

3. **Cleaned pattern-selection-framework.md (persona-specific)**
   - Removed `dependable-go` reference (Go removed from Patina)
   - Replaced Go example with Rust `BuildRunner` trait
   - Updated "Examples in Patina" → "Example Architecture" (Mac-first, LLM-agnostic, Rust+task-specific)
   - **Key insight**: Doc is persona-specific (how YOU think about patterns), not Patina-specific

4. **Validated pattern-selection-framework.md against codebase**
   - **Pattern 1 (Eternal Tools)**: Used everywhere - scrape, init, embeddings (black-box, no versioning)
   - **Pattern 2 (Stable Adapters)**: Claude/Gemini adapters (black-box + versioning + changelog)
   - **Pattern 3 (Evolution Points)**: Not clearly seen in codebase
   - Framework is REAL, not aspirational - code follows it

**Key Decisions:**

1. **ENVIRONMENT.toml is auto-generated** - Don't manually create it, `patina init` generates from Environment::detect()
2. **Pattern-selection-framework is teaching document FOR LLM** - Direct instruction on how to categorize and apply patterns
3. **Need to remove Patina meta-commentary** - Should be pure instruction ("you do X") not philosophy about Patina

**Challenges Faced:**

1. **Confusion about PROJECT_DESIGN.toml** - Exists in Patina repo but removed from user workflow (Oct 21)
   - Solution: Moved to layer/dust/ as historical doc
   - Users get ENVIRONMENT.toml + .patina/config.toml instead

2. **Understanding persona-specific vs Patina-specific**
   - Persona-specific: Cognitive framework that persists (how you think)
   - Patina-specific: Implementation details (what tools we use now)
   - Pattern-selection-framework should be persona-specific

**Patterns Observed:**

1. **"This is how we build Patina" framing** - Clear one-sentence context before pure instruction
2. **Direct LLM instruction ("you") vs meta-commentary ("LLMs")** - More effective teaching
3. **Three patterns actually in use**: Eternal Tools (most code), Stable Adapters (LLM adapters with versioning), Evolution Points (not clearly identified)

**Status**: Pattern-selection-framework cleaned up but needs final edit to remove Patina meta-commentary and make it pure LLM instruction


### 15:21 - Update (covering since 15:19)

**Git Activity:**
- Commits this session:        0
- Files changed: 2
- Last commit: 5 hours ago

**Work Completed:**
- Discussed pattern-selection-framework.md purpose and clarity
- Validated that framework is actually used in codebase (not aspirational)
- Identified need for final edits: remove Patina meta-commentary, make it pure LLM instruction with "This is how we build Patina" framing

**Key Decisions:**
- Pattern-selection-framework.md should be direct instruction TO LLM, not commentary ABOUT LLMs
- Framework is for teaching LLM how to categorize code and apply patterns
- Three patterns are real: Eternal Tools (most code), Stable Adapters (LLM adapters with versioning), Evolution Points (not clearly in use)

**Status**: Session ready to end, changes uncommitted (2 files: CLAUDE.md, pattern-selection-framework.md)


## Session Classification
- Work Type: pattern-work
- Files Changed:        5
- Commits:        3
- Patterns Modified:        3
- Session Tags: session-20251116-091942-start..session-20251116-091942-end
