# Session: Phase 2 Begins Discuss and Design
**ID**: 20251211-140201
**Started**: 2025-12-11T19:02:01Z
**LLM**: claude
**Git Branch**: patina
**Session Tag**: session-20251211-140201-start
**Starting Commit**: cd11b4e66b2453347c96c4315d41076246fe3b91

## Previous Session Context
Last session completed **Phase 1 validation**: fixed the template structure so templates install to `.{frontend}/` subdirectories, updated Gemini adapter to use the centralized `templates::copy_to_project()`, and implemented `patina adapter add` to create adapter files from templates. Key architectural decisions: keep Claude's embedded approach (it has version management), use templates for Gemini/future adapters, defer context.md schema to Phase 2 where MCP will inform the design. The **Orchestration Agent** concept was identified as the key Phase 2/3 focus - an agent that spans MCP + knowledge graph to coordinate tools.

## Goals
- [ ] Phase 2 Begins Discuss and Design

## Activity Log
### 14:02 - Session Start
Session initialized with goal: Phase 2 Begins Discuss and Design
Working on branch: patina
Tagged as: session-20251211-140201-start

### 14:05-15:30 - Orchestration Agent Design Discussion

**Goal:** Explore and design the on-device orchestration agent concept for Phase 2.

**Research Conducted:**
- Searched layer/sessions for prior discussions on orchestration, agents, MLX, local models
- Read key sessions: 20251029-084321 (Layer 3 Intelligent Agent), 20251026-072236 (LLM as orchestrator), 20251120-110914 (progressive adapters, patina thickness), 20251204-173633 (agentic RAG network)
- Reviewed core principles: build.md, dependable-rust.md, unix-philosophy.md, adapter-pattern.md
- Searched dust for archived agent designs

**Key Design Work:**
1. **Identified pain points** from session history:
   - Stuck at semantic only (1/6 dimensions)
   - LLM orchestration burden
   - Context window limits
   - No smart retrieval
   - Privacy concerns
   - Cost/latency of cloud roundtrips

2. **Sketched on-device agent architecture:**
   - Small local LLM (Qwen3-0.6B) for routing/synthesis
   - Multiple oracles: semantic, temporal, session
   - MCP protocol for frontend communication
   - Privacy boundary: sessions never leave device

3. **Integrated with existing commands:**
   - `scrape` feeds the oracles (ingestion)
   - `scry` provides direct oracle access (CLI)
   - `serve` exposes agent via MCP (frontends)

4. **Clarified language stack:**
   - Rust only (no Python)
   - ONNX Runtime via `ort` crate (same as embeddings)
   - TS/Swift only when needed for UI

5. **Documented MCP discovery:**
   - Tool definitions with descriptions
   - Frontend configuration
   - How LLMs learn to use tools

**Artifact Created:**
- `layer/surface/concept-orchestration-agent.md` - Full design concept document

**Key Decisions:**
- On-device agent inverts the model: Patina becomes intelligent middle layer
- Use `ort` crate for both embeddings AND local LLM (ONNX format)
- MCP server via `patina serve` command
- Agent handles routing/combining, frontier LLM handles reasoning

**Open Questions (for next session):**
- MCP transport: stdio vs Unix socket?
- Which small LLM: Qwen3-0.6B vs Phi-3-mini vs OLMo-1B?
- Should `scry --deep` invoke agent?


## Session Classification
- Work Type: exploration
- Files Changed:        0
- Commits:        0
- Patterns Modified:        0
- Session Tags: session-20251211-140201-start..session-20251211-140201-end
