# Session: deep
**ID**: 20251124-220659
**Started**: 2025-11-25T03:06:59Z
**LLM**: claude
**Git Branch**: patina
**Session Tag**: session-20251124-220659-start
**Starting Commit**: 6541d761416ad2d48d9dfe62569e5f435e68062a

## Previous Session Context
Completed Phase 2 (Oxidize) end-to-end: upgraded safetensors 0.4â†’0.7, fixed API compatibility issues using shape inference for dimension loading, and built USearch HNSW index from 1807 projected session events. Documented the adapter dimension architecture showing how each dimension (semantic, temporal, dependency, syntactic, architectural, social) follows the same pattern: SQL query + pairing logic â†’ triplet training. Phase 2 is now 100% complete with semantic adapter working; Phase 2.5 (eval framework) and remaining 5 dimensions are next.

## Goals
- [ ] Deep dive patina direction review

## Activity Log
### 22:06 - Session Start
Session initialized with goal: deep
Working on branch: patina
Tagged as: session-20251124-220659-start

### 22:30 - Comprehensive Direction Review

**Scope:** Deep review of Patina's dimension model architecture, sessions history, spec documents, and MLX strategy.

**Documents Reviewed:**
- `layer/core/build.md` - Roadmap and phase tracking
- `layer/surface/spec-oxidize.md` - Embedding/projection pipeline
- `layer/surface/spec-scry.md` - Query interface spec
- `layer/surface/spec-progressive-adapters.md` - 6-dimension adapter architecture
- `layer/surface/spec-mothership-service.md` - Daemon architecture
- `layer/surface/spec-persona-capture.md` - Cross-project beliefs
- `layer/surface/spec-cross-project.md` - Multi-user workflows
- `layer/surface/spec-eventlog-architecture.md` - LiveStore pattern foundation
- `layer/dust/research-2025/model-strategy-research.md` - MLX + multi-runtime strategy (882 lines)
- Recent sessions: 20251120-110914, 20251116-194408, 20251123-222456, 20251118-155141

**Key Sessions with Critical Context:**
- **20251120-110914**: Progressive adapter architecture, patina thickness model, adapter pattern as system-wide philosophy
- **20251116-194408**: E5-base-v2 benchmark winner (+68%), model registry, dynamic dimension propagation
- **20251123-222456**: MLX research, mlx-rs v0.25, Qwen3 models, multi-runtime strategy

---

## Key Findings

### 1. Current State (What's Built)

| Component | Status |
|-----------|--------|
| Eventlog (16,027 events) | âœ… Complete |
| Scrape Pipeline (git, sessions, code) | âœ… Complete |
| Oxidize (semantic dimension only) | âœ… Complete |
| Scry (query interface) | ðŸ“ Spec only |
| Mothership (daemon) | ðŸ“ Spec only |
| Persona | ðŸ“ Spec only |
| 5 remaining dimensions | ðŸ“ Spec only |

### 2. The Dimension Model Architecture

**Core Concept:** Adapters aren't just ML - they're the unifying design principle at every layer.

```
Layer 1: LLM Adapters        â†’ Claude, Gemini (swappable)
Layer 2: Embedding Models    â†’ E5, BGE, Nomic, Qwen3 (swappable)
Layer 3: Dimension Adapters  â†’ Semantic, Temporal, Dependency, etc (trainable)
Layer 4: Training Data       â†’ Git, Sessions, GitHub (composable)
Layer 5: Storage             â†’ USearch, (future: FAISS, MLX native)
```

**6 Dimensions Documented:**
| Dimension | Training Signal | Data Available | Priority |
|-----------|-----------------|----------------|----------|
| Semantic | Same session = related | 2,174 session events | âœ… Done |
| Temporal | Same commit = related | 707 commits + co_changes | ðŸŽ¯ High |
| Dependency | Caller/callee = related | 9,634 code.call events | ðŸŽ¯ High |
| Syntactic | Similar AST = related | 790 code.function events | Medium |
| Architectural | Same module = related | 13,146 code.* events | Medium |
| Social | Same author = related | 707 commits | Lower |

**Data Source Reality:**
- Only **semantic** requires sessions (lived experience)
- Other 5 dimensions can bootstrap immediately from git + code
- New projects get 5/6 dimensions on day 1, semantic grows over time

### 3. MLX Strategy (Apple Silicon Powerhouse)

**Vision:** Hybrid runtime - ONNX for cross-platform, MLX for Mac-native performance.

**Key Details:**
- `mlx-rs` v0.25 (Feb 2025, production-ready)
- Feature flag: `cargo build --features mlx`
- Mac Studio M2 Max: ~100 embed/sec (MLX) vs ~30 embed/sec (ONNX)
- Unified memory enables Qwen3-Embed-8B (4096 dims, ~16GB)

**Model Progression:**
| Model | Dims | Runtime | Use Case |
|-------|------|---------|----------|
| E5-base-v2 | 768 | ONNX | Current baseline |
| Qwen3-Embed-0.6B | 1024 | ONNX | Code-aware, low-risk upgrade |
| Qwen3-Embed-4B | 2560 | MLX | Production target |
| Qwen3-Embed-8B | 4096 | MLX | Max quality |

**Critical Insight:** Projections are children of embedding model. Change base model â†’ retrain all projections. Architecture handles this via `embedder.dimension()` propagation.

### 4. Existing EmbeddingEngine Trait (Already Plug-and-Play)

```rust
pub trait EmbeddingEngine {
    fn embed(&mut self, text: &str) -> Result<Vec<f32>>;
    fn embed_query(&mut self, text: &str) -> Result<Vec<f32>>;   // Asymmetric
    fn embed_passage(&mut self, text: &str) -> Result<Vec<f32>>; // Asymmetric
    fn embed_batch(&mut self, texts: &[String]) -> Result<Vec<Vec<f32>>>;
    fn dimension(&self) -> usize;  // KEY: Auto-adapts everything
    fn model_name(&self) -> &str;
}
```

No refactor needed - just add `MlxEmbedder` implementation later.

---

## Decision: Path C

**Chosen approach:** Build 2-3 high-value dimensions, then Scry, then validate before full 6-dimension investment.

### Phase 2.5: Complete Dimension Model (Now)
1. **Temporal dimension** - Uses git co_changes (already materialized), simpler pairing
2. **Dependency dimension** - Uses call graph (9,634 events), richer signal
3. Each dimension ~200 lines (SQL query + pairing logic in `src/commands/oxidize/pairs/`)

### Phase 3: Scry (After 3 dimensions working)
- Vector search across dimensions
- SQLite metadata enrichment
- `patina scry "query"` â†’ tagged results

### Phase 2B-MLX: (After validation)
- Add `mlx-rs` with feature flag
- Upgrade to Qwen3 models
- Retrain all projections with better base embeddings

---

## Architecture Decisions Confirmed

1. **Concatenation for now** - All dimensions into one vector (~2,304-dim with all 6)
   - Can revisit separate indices if needed

2. **Recipe-driven model selection** - Future oxidize.yaml:
   ```yaml
   embedding_model: e5-base-v2  # Swappable
   runtime: auto                # onnx | mlx | auto
   projections:
     semantic: { layers: [768, 1024, 256] }
     temporal: { layers: [768, 1024, 256] }
   ```

3. **Dimension propagates automatically** - `embedder.dimension()` â†’ projection layers â†’ safetensors â†’ USearch

4. **MLX is additive, not replacement** - ONNX stays for cross-platform, MLX enables bigger models on Mac

---

## Open Questions (for next session)

1. **Temporal vs Dependency first?**
   - Temporal: simpler (co_changes table exists)
   - Dependency: richer signal (call graph)

2. **Query-time dimension weighting?**
   - Spec shows: `patina query --temporal 2.0 "recent changes"`
   - How does LLM know which weights to use?

3. **Scry before or after 2nd dimension?**
   - Could validate with 1 dimension first
   - Or wait for 2-3 to test multi-dimension search

---

## Key Files for Implementation

**Dimension pair generators:**
- `src/commands/oxidize/pairs/mod.rs` - Existing semantic pairs
- Need: `temporal.rs`, `dependency.rs` (each ~200 lines)

**Model/runtime abstraction:**
- `src/embeddings/mod.rs` - EmbeddingEngine trait
- `src/embeddings/onnx.rs` - Current ONNX impl
- Need: `src/embeddings/mlx.rs` (future)

**Registry:**
- `resources/models/registry.toml` - 5 models defined, E5 production

**Specs:**
- `layer/surface/spec-oxidize.md` - Projection pipeline
- `layer/dust/research-2025/model-strategy-research.md` - MLX strategy (882 lines)


## Session Classification
- Work Type: exploration
- Files Changed:        0
- Commits:        0
- Patterns Modified:        0
- Session Tags: session-20251124-220659-start..session-20251124-220659-end
