# Session: patina-llm-driven-neuro-symbolic-knowledge-system
**ID**: 20251116-194408
**Started**: 2025-11-17T00:44:08Z
**LLM**: claude
**Git Branch**: neuro-symbolic-knowledge-system
**Session Tag**: session-20251116-194408-start
**Starting Commit**: 795e64e5dc57ebc75a1c9cdd18bd4a8db9c395f6

## Previous Session Context
Implemented and validated asymmetric embedding support across 4 production models (all-MiniLM, BGE-small, BGE-base, E5-base), adding dynamic dimension support (384/768), model-specific query/passage prefixes, and seamless config-driven model switching. Fixed dimension mismatch bug and prefix requirements for BGE/E5 models, with E5-base-v2 emerging as best performer (+56% similarity improvement). Model abstraction is complete and ready for Phase 1A event sourcing.

## Goals
- [ ] patina-llm-driven-neuro-symbolic-knowledge-system

## Activity Log
### 19:44 - Session Start
Session initialized with goal: patina-llm-driven-neuro-symbolic-knowledge-system
Working on branch: neuro-symbolic-knowledge-system
Tagged as: session-20251116-194408-start

### 20:44 - Embedding Model Deep Dive & Nomic Benchmark

**Work Completed:**

1. **Explored Embedding Landscape for Apple Silicon**
   - Surveyed cutting-edge models: Nomic Embed v1.5, BGE-M3, Snowflake Arctic, Jina v2, E5-Mistral-7B
   - Analyzed EmbeddingGemma (2.5B params) - concluded too large for marginal gains
   - Evaluated ONNX+CoreML vs Rust-native (candle+Metal) approaches
   - Decided to stick with ONNX Runtime for cross-platform compatibility
   - Identified GTE-base as "orphaned" - no differentiation vs E5/Nomic

2. **Added Nomic Embed v1.5 to Model Registry**
   - Downloaded quantized ONNX model (137MB) and tokenizer (711KB)
   - Added registry entry with query/passage prefixes: "search_query: " / "search_document: "
   - Verified existing abstraction handles Nomic without code changes
   - Dimensions: 768, Context: 8192 tokens (vs 512 for others), MTEB: 62.4

3. **Benchmarked 5 Models Head-to-Head**
   - Updated `scripts/benchmark-models.sh` to test all 5 downloaded models
   - Ran 5 queries against 992 observations for each model
   - Generated benchmark report: `tests/model-benchmarks/benchmark-20251116-203552.md`

**Benchmark Results:**

| Rank | Model | Avg Similarity | vs Baseline | Size |
|------|-------|----------------|-------------|------|
| ðŸ¥‡ | **e5-base-v2** | **0.8345** | **+68%** | 105MB |
| ðŸ¥ˆ | bge-base-en-v1.5 | 0.7069 | +42% | 105MB |
| ðŸ¥‰ | nomic-embed-text-v1.5 | 0.6917 | +39% | 137MB |
| 4th | bge-small-en-v1.5 | 0.6758 | +36% | 32MB |
| 5th | all-minilm-l6-v2 | 0.4965 | baseline | 23MB |

**Key Findings:**

- **E5-base-v2 won decisively** (20.6% better than Nomic) despite lower MTEB score (61.5 vs 62.4)
- **Domain trumps benchmarks**: E5's asymmetric Q&A training perfect for "how do I..." queries
- **Nomic's 8192 context is overkill** for short Rust patterns (queries: 5-10 words, docs: 1-2 sentences)
- **E5 won all 5 queries** - perfect sweep, no contest
- **MTEB â‰  real-world performance** - test on your actual data!

**Why E5 Won:**
1. Asymmetric query/passage prefixes match Q&A pattern
2. Training likely includes Stack Overflow-style Q&A
3. 512 token context is sufficient for concise patterns
4. Specialized for retrieval (vs Nomic's general SOTA)

**Decision:**
- **Production model: e5-base-v2** (proven champion, 68% better than baseline)
- Skip GTE-base (minimal differentiation, 62.39 MTEB)
- Nomic useful for future long-form docs (>1000 tokens) or multilingual support

**Files Changed:**
- `resources/models/registry.toml` - Added Nomic v1.5 entry
- `scripts/benchmark-models.sh` - Updated to test 5 models
- `tests/model-benchmarks/benchmark-20251116-203552.md` - Full results report
- `.patina/config.toml` - Temporarily switched to Nomic for testing

**Status**: Model evaluation complete. E5-base-v2 validated as best choice for Patina's code pattern retrieval.


### 22:14 - Update (covering since 19:44)

**Git Activity:**
- Commits this session:        2
- Files changed: 52 total (50 in main commit, 1 in fix)
- Last commit: 39 seconds ago

**Work Completed:**

1. **Implemented CI-Driven Active Model Testing**
   - Created `scripts/get-active-model.sh` to extract model from `.patina/config.toml`
   - Created `scripts/download-model.sh` for model-specific downloads from registry
   - Created `scripts/download-active-model.sh` to download active + baseline models
   - Updated CI workflow to cache models based on active model + registry hash
   - CI now tests production model (e5-base-v2) instead of hardcoded baseline

2. **Fixed Multi-Dimension Support Throughout Codebase**
   - Added `BeliefStorage::open_with_dimension()` (was hardcoded to 384-dim)
   - Updated `SemanticSearch::new()` to pass embedder dimension to both storages
   - Fixed all integration test helpers to use active model with baseline fallback
   - Made test assertions model-agnostic (no hardcoded dimensions)

3. **Resolved Test Failures Across All Environments**
   - Fixed 4 integration test files using old `new_from_paths()` API (2â†’6 params)
   - Fixed `test_belief_semantic_search` - changed from exact ranking to top-N check
   - E5-base-v2 ranks results differently than all-minilm (both valid, just different)
   - All 93 tests passing locally and in CI

4. **Git Workflow & PR Creation**
   - Untracked all model files from git (download on-demand strategy)
   - Added 35 new files (scripts, benchmarks, session)
   - Created PR #41 with comprehensive benchmark results
   - Fixed CI failure and pushed update

**Key Decisions:**

1. **Test Both Active + Baseline Models in CI**
   - Unit tests: Use baseline (all-minilm, 384-dim) for consistent fast tests
   - Integration tests: Use active model (e5-base-v2, 768-dim) for production validation
   - Downloads both if different, giving test coverage of production model

2. **Model-Agnostic Test Assertions**
   - Changed from `assert_eq!(dim, 384)` to `assert_eq!(dim, embedder.dimension())`
   - Changed exact ranking assertions to top-N checks
   - Tests now pass with any model (384 or 768-dim)

3. **Download-on-Demand for Models**
   - Removed all model binaries from git (cleaned 3 tracked files)
   - Updated `.gitignore` to exclude `resources/models/*/`
   - CI downloads models first run (~30s), caches for subsequent runs (0s)

**Challenges Faced:**

1. **Integration Tests Failed - Vector Dimension Mismatch**
   - Problem: BeliefStorage hardcoded to 384 dimensions, e5-base-v2 is 768
   - Root cause: Only ObservationStorage had `open_with_dimension()`, not BeliefStorage
   - Solution: Added matching API to BeliefStorage, updated SemanticSearch
   - Result: Both storages now accept dynamic dimensions

2. **Old API Signatures in 4 Test Files**
   - Problem: `OnnxEmbedder::new_from_paths()` changed from 2â†’6 params
   - Root cause: Previous refactor added model_name, dimension, prefixes
   - Solution: Updated all test helpers with new 6-param signature
   - Result: All integration tests compile and pass

3. **CI Failed - Test Expected Exact Ranking**
   - Problem: `test_belief_semantic_search` asserted "values_type_safety" must be #1
   - Root cause: E5-base-v2 ranked "prefers_rust_for_cli_tools" slightly higher (0.993 vs 0.981)
   - Solution: Changed to "must be in top 2" instead of "must be #1"
   - Result: Test is model-agnostic, passes with both baseline and active models

**Patterns Observed:**

1. **Different Models, Different Rankings (Both Valid)**
   - E5-base-v2 and all-minilm rank semantic similarity differently
   - Both return semantically related results, just in different order
   - Tests should check semantic correctness, not exact ranking
   - Lesson: Avoid brittle assertions on model-specific behavior

2. **Dynamic Dimension Propagation**
   - Pattern: `embedder.dimension()` â†’ storage APIs â†’ USearch index creation
   - Single source of truth: ModelDefinition.dimensions in registry
   - No magic numbers scattered through code
   - Clean: Change model in config, everything adapts automatically

3. **CI Cache Strategy for Large Binary Assets**
   - Cache key: `models-{active_model}-{registry_hash}`
   - Invalidates when model changes OR registry updates
   - First run downloads, subsequent runs instant
   - Saves ~30s per CI run after first build

4. **Option B Pattern for Test Helpers**
   - Try active/production model first
   - Fall back to known baseline if unavailable
   - Gives best of both worlds: production testing + local dev robustness
   - Used consistently across all integration test files

**Status**: PR #41 created and CI passing. Ready to merge to main.


## Session Classification
- Work Type: pattern-work
- Files Changed:       50
- Commits:        2
- Patterns Modified:        4
- Session Tags: session-20251116-194408-start..session-20251116-194408-end
