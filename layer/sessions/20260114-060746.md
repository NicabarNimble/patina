# Session: spec-ref-repo-health
**ID**: 20260114-060746
**Started**: 2026-01-14T11:07:46Z
**LLM**: claude
**Git Branch**: patina
**Session Tag**: session-20260114-060746-start
**Starting Commit**: a4f6ee319cb36d70da07f2269982dd09b4d711fa

## Previous Session Context
Last session ("adapter-polish") pivoted from adapter research to fixing critical data health issues. Key accomplishments: diagnosed `.patina/data/` → `.patina/local/data/` path migration that had orphaned 47MB of index data, fixed gitignore, ran migration script on 14 ref repos recovering 925 claude-code issues. Created `spec-ref-repo-health.md` spec covering bulk issue sync and rate limit handling. Ready to implement that spec now.

## Goals
- [ ] spec-ref-repo-health

## Activity Log
### 06:07 - Session Start
Session initialized with goal: spec-ref-repo-health
Working on branch: patina
Tagged as: session-20260114-060746-start


### 08:49 - Update (covering since 06:07)

**Git Activity:**
- Commits this session: 0
- Files changed: 7
- Last commit: 9 hours ago

**Work Completed:**
1. **Reviewed spec-ref-repo-health.md** - Discussed Phase 2 (bulk issue sync) in depth
2. **Identified core problem** - Current code uses individual API calls (18k calls) when bulk API exists (180 calls)
3. **Created spec-forge-bulk-fetch.md** - New focused spec for the bulk fetch fix
4. **Validated approach** - Changed `limit: 500` → `limit: 50000` and tested:
   - gemini-cli: 8,565 issues in 2:15
   - opencode: 5,161 issues in 1:37
   - claude-code: 17,509 issues in 3:20 (vs 3.7 hours with old approach)
5. **Identified remaining work** - `discover_all_issues()` still runs wastefully, PRs not bulk fetched

**Key Decisions:**
1. Query counts first for progress reporting and validation (not over-engineering)
2. 50% rate limit budget is intentional design decision, not arbitrary
3. Keep background sync infrastructure, just fix the fetch strategy
4. Delete `discover_all_issues()` - the wasteful function that creates ref backlog after bulk fetch

**Discussion Context:**
- Reviewed spec through lens of Eskil/Gjengset/Ng - pushed back on dismissive critiques
- User correctly noted: knowing counts is system knowledge, not over-engineering
- Pre-requisite test validates bulk approach works before full implementation

**Patterns Observed:**
- Simple limit change (500→50000) was the core fix
- `gh` CLI handles pagination internally - no need to reimplement
- Existing code had two competing strategies: bulk fetch + ref backlog (wasteful)


## Session Classification
- Work Type: exploration
- Files Changed:        0
- Commits:        0
- Patterns Modified:        0
- Session Tags: session-20260114-060746-start..session-20260114-060746-end
