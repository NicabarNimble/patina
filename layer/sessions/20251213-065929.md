# Session: Phase 2.5 Review and Finish
**ID**: 20251213-065929
**Started**: 2025-12-13T11:59:29Z
**LLM**: claude
**Git Branch**: patina
**Session Tag**: session-20251213-065929-start
**Starting Commit**: 0e4b34611ddffcf6db60087d9ef05efd3e2360e8

## Previous Session Context
Last session built **Phase 2.5b benchmark infrastructure** (`patina bench retrieval`) and discovered a critical gap: code facts from `patina scrape code` were indexed but never embedded in the semantic search. Fixed the pipeline by adding code facts to `oxidize` with dual ID space (1B+ offset) and updated `scry` enrichment to handle both eventlog and function_facts. Results: **10x MRR improvement** (0.017 → 0.176), Recall@10 jumped from 5% to 31.7%. Deferred CodeOracle to Phase 3 since current retrieval is functional.

## Goals
- [x] Phase 2.5a: Retrieval Configuration
- [x] Phase 2.5c: Model Flexibility
- [ ] **Phase 2.5e: Lab Calibration** (discovered this session - required for true completion)

## Activity Log
### 06:59 - Session Start
Session initialized with goal: Phase 2.5 Review and Finish
Working on branch: patina
Tagged as: session-20251213-065929-start

### 07:00 - Core Values Review
Reviewed and grounded work in:
- `dependable-rust.md` - Black-box module pattern
- `unix-philosophy.md` - Single responsibility, composition
- `adapter-pattern.md` - Trait-based external system bridges

### 07:15 - Architecture Analysis
Verified current retrieval implementation aligns with core values:
- `retrieval/mod.rs` exports only `QueryEngine` + `FusedResult` ✅
- Oracle is correctly a strategy pattern, not adapter pattern ✅
- Composition: scry → Oracle → QueryEngine → fusion → MCP ✅

### 07:30 - Phase 2.5a: Retrieval Configuration
**Implemented:**
1. Added `RetrievalSection` to `ProjectConfig` with:
   - `rrf_k` (default: 60) - RRF smoothing constant from Cormack et al.
   - `fetch_multiplier` (default: 2) - Over-fetch factor for fusion
2. Added `RetrievalConfig` to `QueryEngine` with `with_config()` constructor
3. Added CLI overrides to `patina bench`: `--rrf-k`, `--fetch-multiplier`
4. Bench command now displays config values in output

**Files Changed:**
- `src/project/internal.rs` - Added `RetrievalSection`
- `src/project/mod.rs` - Export `RetrievalSection`
- `src/retrieval/engine.rs` - Added `RetrievalConfig`, `with_config()`
- `src/retrieval/mod.rs` - Export `RetrievalConfig`
- `src/commands/bench/mod.rs` - Added CLI options
- `src/commands/bench/internal.rs` - Config loading and display
- `src/commands/init/internal/config.rs` - Include retrieval in init
- `src/main.rs` - CLI args for bench

### 07:45 - Phase 2.5c: Model Flexibility
**Implemented:**
1. Updated `scry/mod.rs` to read embedding model from config
2. Updated `semantic.rs` oracle to read embedding model from config
3. Paths now dynamically constructed from config model name
4. Documented model addition process in `build.md`

**Key Design Decision:**
Model change requires rebuilding index (`patina oxidize`) because:
- Different models have different embedding dimensions
- Vector spaces are not compatible across models

**Files Changed:**
- `src/commands/scry/mod.rs` - Added `get_embedding_model()`
- `src/retrieval/oracles/semantic.rs` - Dynamic path construction
- `layer/core/build.md` - Model addition documentation

### 08:00 - Validation
- All tests pass (84 lib + 47 bin)
- Clippy clean
- Formatting verified
- Bench command works with custom config values

### 08:30 - PhD ML Review (Andrew Ng / Amidi Analysis)

Applied rigorous ML evaluation lens to Phase 2.5. Key findings:

**What's Good:**
- RRF fusion implementation is correct (Cormack et al. 2009)
- Benchmark infrastructure exists with MRR, Recall@K, latency
- Configurable parameters for experimentation

**Critical Gap - Ground Truth Quality:**
- Current benchmark uses **keywords** as relevance proxy
- `{"relevant": ["RRF", "fusion"]}` ← keyword matching, not document relevance
- A doc mentioning "fusion" isn't necessarily relevant to "how does fusion work"
- **Data > Code**: The benchmark code is correct, but labels are weak

**Missing Capabilities:**
- No oracle ablation (`--oracle semantic` vs `--oracle lexical`)
- Can't measure which retrieval source is helping or hurting
- Recall@K counts keywords, should count documents

### 09:00 - Lab Walkthroughs

Designed three practical lab use cases:
1. **"Why didn't Claude find X?"** - Diagnose retrieval failures with ablation
2. **"Is CodeOracle worth building?"** - Data-driven roadmap decisions
3. **"Which sessions to distill?"** - Quality over quantity in persona

Also explored power-user scenarios:
4. **Hackathon Mode** - Cross-project learning via persona
5. **Contributor Mode** - Understanding external repos

### 09:30 - Patina Architecture Clarification

**Key Insight from Discussion:**

```
┌─────────────────────────────────────────────┐
│  FRONTENDS (Claude / Gemini / Codex)        │
│  - Swappable "main brain"                   │
│  - CONTRIBUTES to Patina (writes sessions)  │
│  - USES Patina (queries for context)        │
└─────────────────────────────────────────────┘
                    ↕ MCP
┌─────────────────────────────────────────────┐
│  PATINA INSIDES (on-device)                 │
│  - Oracles, Fusion, Indexing                │
│  - THE LAB (measurement)                    │
│  - Frontend-agnostic                        │
└─────────────────────────────────────────────┘
```

**Temporal Reality:**
- Mature Patina projects: Rich sessions + code + git
- New Patina projects: Little session data
- External repos: No sessions, git quality varies

**The Dogfood Principle:**
- Patina itself is the best test case (rich data)
- Lab should work on Patina first
- Phase 3 handles graceful degradation for sparse projects

### 09:45 - The Simpler Path (Andrew Ng Approved)

**Realization:** We don't need LLM-in-the-loop evaluation for 2.5.

Ground truth can come from domain knowledge:
- File names are meaningful (`fusion.rs` is about fusion)
- Sessions capture intent ("Built RRF fusion because...")
- Code structure is semantic (module paths, function names)

**For queries like "How does RRF work?"**
- Relevant: `src/retrieval/fusion.rs` (implementation)
- Relevant: Session where RRF was built (context/decisions)
- We KNOW these are correct without LLM help

**LLMs wrote most of the code**, but:
- Sessions capture WHAT was asked
- File names capture WHAT was built
- We can validate the lab on Patina itself

## Key Decisions

1. **Phase 2.5e Created** - Lab Calibration required for true completion
2. **Dogfood First** - Validate lab on Patina before other projects
3. **Data > Code** - Fix ground truth format before adding metrics
4. **Unix Philosophy** - `--oracle` flag for composition, not new commands
5. **Phase 3 Scope** - Graceful degradation for new/external projects

## What Remains for 2.5 Completion

| Task | Type | Effort |
|------|------|--------|
| Fix benchmark format (doc IDs) | Data | 1h |
| Add `--oracle` ablation flag | Code | 1h |
| Fix Recall@K for doc ID matching | Code | 30m |
| Create ~20 Patina dogfood queries | Data | 2h |

## Insights for Next Session

- Start with creating dogfood queries - this is the highest value work
- Ground truth = sessions that built feature + code that implements it
- Oracle ablation is simple: filter oracles by name in QueryEngine
- Don't over-engineer: simple doc ID matching is sufficient


## Session Classification
- Work Type: exploration
- Files Changed:        0
- Commits:        0
- Patterns Modified:        0
- Session Tags: session-20251213-065929-start..session-20251213-065929-end
