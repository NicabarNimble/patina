# Stable Parsing Engine - TODO

## Current Status: Production Ready âœ…

The refactored parsing engine is complete with 100% feature parity plus bug fixes.

## Completed Features âœ…

### Core Extraction Pipeline
- âœ… Modular architecture (5 specialized modules)
- âœ… All 6 languages supported (Rust, Go, Python, JS/TS, Solidity)
- âœ… AST processing with tree-sitter
- âœ… Storage abstraction layer
- âœ… DuckDB backend implementation

### Feature Complete
- âœ… **Function extraction** with full metadata
- âœ… **Type extraction** (structs, traits, enums)
- âœ… **Import tracking** with external/internal classification
- âœ… **Documentation extraction** with keyword search
- âœ… **Call graph** with line numbers
- âœ… **Behavioral hints** (unwrap, expect, panic, unsafe)
- âœ… **Code fingerprints** (AST-based)
- âœ… **Incremental updates** (mtime-based)
- âœ… **Git metrics** extraction
- âœ… **Pattern references** from markdown

### Bugs Fixed
- âœ… Call graph 11x duplication bug
- âœ… Force flag incomplete table clearing
- âœ… SQL injection vulnerabilities
- âœ… Schema column mismatches
- âœ… Missing impl block processing

## Next Phase: Context Retrieval System ðŸš€

### Phase 1: Query Interface (Priority: HIGH)
Create a context retrieval system that answers questions using the extracted knowledge.

```rust
// src/context/mod.rs
pub struct ContextBuilder {
    store: DuckDbStore,
    max_tokens: usize,
}

impl ContextBuilder {
    pub fn query(&self, question: &str) -> Context {
        // 1. Extract keywords from question
        // 2. Find relevant symbols via documentation
        // 3. Expand via call graph
        // 4. Assemble facts
        // 5. Rank by relevance
    }
}
```

**Tasks:**
- [ ] Create `src/context/` module structure
- [ ] Implement keyword extraction from questions
- [ ] Build relevance ranking algorithm
- [ ] Add recursive graph traversal
- [ ] Create context assembly logic

### Phase 2: LLM Formatter (Priority: HIGH)
Format the retrieved context optimally for different LLMs.

```rust
pub trait LLMFormatter {
    fn format(&self, context: Context) -> String;
}

pub struct ClaudeFormatter;
pub struct GPTFormatter;
pub struct GeminiFormatter;
```

**Tasks:**
- [ ] Define context format specifications
- [ ] Implement formatters for major LLMs
- [ ] Add token counting/budgeting
- [ ] Create prompt templates
- [ ] Handle context overflow gracefully

### Phase 3: CLI Commands (Priority: MEDIUM)
Add user-friendly commands for context retrieval.

```bash
# Query for context
patina context "How does authentication work?"

# With options
patina context "Build system" --max-tokens 3000 --format claude

# Export context
patina context "Error handling" --output context.md
```

**Tasks:**
- [ ] Add `context` subcommand to CLI
- [ ] Implement question parsing
- [ ] Add format selection flags
- [ ] Create output options
- [ ] Add interactive mode

### Phase 4: Advanced Features (Priority: LOW)

#### Cross-Repository Analysis
- [ ] Support multiple repos in single query
- [ ] Cross-reference shared patterns
- [ ] Identify common dependencies

#### Method Recognition in Impl Blocks
- [ ] Parse methods inside impl blocks
- [ ] Associate methods with their types
- [ ] Track trait implementations

#### Change Impact Analysis
- [ ] Track which functions are affected by changes
- [ ] Build dependency graphs
- [ ] Suggest test targets

## Testing Requirements

### Integration Tests Needed
- [ ] Test each language parser separately
- [ ] Verify call graph accuracy
- [ ] Validate documentation extraction
- [ ] Test incremental updates
- [ ] Benchmark performance on large repos

### Test Repositories
- [ ] Small (< 100 files): Simple examples
- [ ] Medium (100-1000 files): Patina itself
- [ ] Large (1000+ files): Dagger, Dust
- [ ] Multi-language: Mixed codebases

## Documentation Needs

### User Documentation
- [ ] Installation guide
- [ ] Quick start tutorial
- [ ] Query examples
- [ ] Language-specific notes
- [ ] Performance tuning guide

### Developer Documentation
- [ ] Module architecture guide
- [ ] Adding new languages
- [ ] Storage backend interface
- [ ] Contributing guidelines

## Performance Optimizations

### Consider for v2
- [ ] Parallel file processing
- [ ] Streaming parser for large files
- [ ] Query result caching
- [ ] Compressed storage format
- [ ] Background incremental updates

## Known Limitations

### Current
1. Methods in impl blocks not recognized as separate functions
2. No cross-file type inference
3. No macro expansion (Rust)
4. No template instantiation tracking (C++)
5. Dynamic language limitations (Python, JS)

### Won't Fix (By Design)
1. Runtime behavior analysis (static only)
2. External dependency parsing (local only)
3. Binary file analysis
4. Natural language understanding of code logic

## Success Metrics

### Performance Targets
- Extract 1,000 files in < 10 seconds
- Query response in < 100ms
- Context generation in < 1 second
- Database size < 5MB per 1,000 files

### Quality Targets
- 95% function detection accuracy
- 90% call graph completeness
- 80% documentation coverage (public APIs)
- Zero false positives in behavioral hints

## Timeline Estimate

### Week 1-2: Context Retrieval
Build the query interface and basic retrieval

### Week 3-4: LLM Integration
Add formatters and token management

### Week 5-6: Polish & Testing
CLI improvements, documentation, testing

### Week 7-8: Advanced Features
Cross-repo, impact analysis, optimizations

## Notes

The core extraction engine is complete and production-ready. The next phase focuses on making the extracted knowledge easily accessible and useful for LLM-powered development workflows. Each phase can be shipped independently for incremental value delivery.